{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Deterministic guarantees with Output Range Analysis\n",
    "In this tutorial we will show how to guarantee feasibility and even stability for AMPC on linear systems using Output Range Analysis. First, we will define our system and train an AMPC using do-mpc."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "from casadi import *\n",
    "from do_mpc.tools import Timer\n",
    "import jdc\n",
    "# Add do_mpc to path. This is not necessary if it was installed via pip\n",
    "import os\n",
    "rel_do_mpc_path = os.path.join('..','..','..')\n",
    "sys.path.append(rel_do_mpc_path)\n",
    "\n",
    "# Import do_mpc package:\n",
    "import do_mpc"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model\n",
    "We consider the oscillating mass example as described in the original paper and in our do-it-yourself AMPC notebook. That is the model is defined as a discrete 2D-model\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model_type = 'discrete' # either 'discrete' or 'continuous'\n",
    "model = do_mpc.model.Model(model_type)\n",
    "x=model.set_variable('_x','x',(2,1))\n",
    "u=model.set_variable('_u','u')\n",
    "A=np.array([[0.5403, -0.8415],[0.8415, 0.5403]])\n",
    "B=np.array([[-0.4597],[0.8415]])\n",
    "model.set_rhs('x',A@x+B@u)\n",
    "model.setup()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Calculate LQR gain, MPI set for stability\n",
    "Now there is one difference. We are now looking to stabilize our MPC and later our AMPC. For this, we need to get the LQR feedback controller and the control invariant set in which we ensure to remain, if the LQR is used. Additionally, we need the terminal cost. The following algorithm iteratively computes this maximum control invariant set"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "from control import dare\n",
    "from pypoman import compute_polytope_vertices\n",
    "from pypoman.polygon import plot_polygon\n",
    "from numpy.linalg import matrix_power as mp\n",
    "\n",
    "# state constraints matrix\n",
    "F = np.array([[1 / 5, 0],\n",
    "              [-1 / 5, 0],\n",
    "              [0, 1 / 5],\n",
    "              [0, -1 / 5]])\n",
    "\n",
    "# input constraints matrix\n",
    "G = np.array([[1],\n",
    "              [-1]])\n",
    "\n",
    "Q=np.array([[2,0],[0,2]])\n",
    "\n",
    "R=np.array([1])\n",
    "\n",
    "# Compute optimal feedback matrix by solving the DARE\n",
    "P_lqr, _, K_lqr = dare(A, B, Q, R)\n",
    "print(K_lqr)\n",
    "\n",
    "# convert to numpy array\n",
    "K_lqr = -np.array(K_lqr)\n",
    "\n",
    "# Update the closed-loop\n",
    "A_cl = A + B @ K_lqr\n",
    "# Maximum number of iterations\n",
    "max_iter = 100\n",
    "print(A_cl)\n",
    "\n",
    "# Initialize matrix describing the invariant set\n",
    "invariant_mat = np.zeros((0, 2))\n",
    "\n",
    "# run loop\n",
    "for n_f in range(max_iter):\n",
    "\n",
    "    # extend the matrix describing the invariant set\n",
    "    invariant_mat = np.vstack([invariant_mat, F @ mp(A_cl, n_f), G @ K_lqr @ mp(A_cl, n_f)])\n",
    "\n",
    "    # termination criterion\n",
    "    one_vec = np.ones((invariant_mat.shape[0], 1))\n",
    "\n",
    "    # compute vertices of current iterate of the maximum invariant set\n",
    "    verts = compute_polytope_vertices(invariant_mat, one_vec)\n",
    "\n",
    "    # compute predecessor states of the current vertices\n",
    "    verts_next = [A_cl @ np.reshape(vert, (-1, 1)) for vert in verts]\n",
    "\n",
    "    # check if all verts lie inside the current iterate of the maximum invariant set\n",
    "    in_omega = [all(invariant_mat @ vert <= one_vec) for vert in verts_next]\n",
    "\n",
    "    # if all predecessor verts inside the current iterate of the maximum invariant set -> break\n",
    "    if all(in_omega):\n",
    "        print('Algorithm converged after ' + str(n_f + 1) + ' step(s).')\n",
    "        break\n",
    "plot_polygon(verts,color='r',alpha=0.4,resize=True)\n",
    "#print(invariant_mat)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## MPC\n",
    "Now we can use this MPI set as the terminal set, the cost of the LQR as the terminal cost in our MPC. This adapts the MPC to the following code in do-mpc"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\smjsadam\\Documents\\Job\\Forschung\\Code\\2025-workshop-dycops\\do_mpc\\controller\\_mpc.py:885: UserWarning: rterm was not set and defaults to zero. Changes in the control inputs are not penalized. Can lead to oscillatory behavior.\n",
      "  warnings.warn('rterm was not set and defaults to zero. Changes in the control inputs are not penalized. Can lead to oscillatory behavior.')\n"
     ]
    }
   ],
   "source": [
    "mpc = do_mpc.controller.MPC(model)\n",
    "setup_mpc = {\n",
    "    'n_horizon': 3,\n",
    "    'n_robust': 0,\n",
    "    'open_loop': 0,\n",
    "    't_step': 0.1,\n",
    "}\n",
    "mpc.set_param(**setup_mpc)\n",
    "mpc.settings.supress_ipopt_output()\n",
    "_x=model.x['x']\n",
    "_u=model.u['u']\n",
    "lterm=_x.T@Q@_x+_u.T@R@_u\n",
    "mterm=_x.T@P_lqr@_x\n",
    "mpc.set_objective(mterm,lterm)\n",
    "\n",
    "mpc.bounds['lower','_x','x']=np.array([[-5],[-5]])\n",
    "mpc.bounds['upper','_x','x']=np.array([[5],[5]])\n",
    "mpc.bounds['lower','_u','u']=np.array([[-1]])\n",
    "mpc.bounds['upper','_u','u']=np.array([[1]])\n",
    "mpc.prepare_nlp()\n",
    "#print(mpc.opt_x['_x'])\n",
    "extra_cons= invariant_mat@mpc.opt_x['_x', -1, 0][0][0:2]-1\n",
    "mpc.nlp_cons.append(\n",
    "       extra_cons\n",
    "    )\n",
    "mtx=np.zeros(extra_cons.shape)\n",
    "mtx.fill(-inf)\n",
    "\n",
    "mpc.nlp_cons_lb.append(mtx)\n",
    "mpc.nlp_cons_ub.append(np.zeros(extra_cons.shape))\n",
    "mpc.create_nlp()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Estimator and Simulator\n",
    "Estimator and Simulator remain the same."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "estimator = do_mpc.estimator.StateFeedback(model)\n",
    "simulator=do_mpc.simulator.Simulator(model)\n",
    "simulator.set_param(t_step = 0.1)\n",
    "simulator.setup()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Visualization and closed-loop simulation\n",
    "Of course, we can again visualize our stable MPC."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "np.random.seed(99)\n",
    "\n",
    "# Initial state\n",
    "mpc.reset_history()\n",
    "simulator.reset_history()\n",
    "e = np.ones([model.n_x,1])\n",
    "x0 = np.random.uniform(-3*e,3*e) # Values between +3 and +3 for all states\n",
    "mpc.x0 = x0\n",
    "print(x0)\n",
    "simulator.x0 = x0\n",
    "estimator.x0 = x0\n",
    "\n",
    "# Use initial state to set the initial guess.\n",
    "mpc.set_initial_guess()\n",
    "for k in range(10):\n",
    "    u0 = mpc.make_step(x0)\n",
    "    y_next = simulator.make_step(u0)\n",
    "    x0 = estimator.make_step(y_next)\n",
    "from matplotlib import rcParams\n",
    "rcParams['axes.grid'] = True\n",
    "rcParams['font.size'] = 18\n",
    "fig, ax, graphics = do_mpc.graphics.default_plot(mpc.data, figsize=(16,9))\n",
    "graphics.plot_results()\n",
    "graphics.reset_axes()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Approximate MPC\n",
    "Now lets define our approximate MPC as before in the first notebook. We see how efficiently we can generate the AMPC using do-mpc"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "approx_mpc=do_mpc.approximateMPC.ApproxMPC(mpc)\n",
    "approx_mpc.settings.act_fn='relu'\n",
    "n_l=10\n",
    "L=1\n",
    "approx_mpc.settings.n_hidden_layers=L\n",
    "approx_mpc.settings.n_neurons=n_l\n",
    "approx_mpc.settings.scaling=False\n",
    "approx_mpc.setup()\n",
    "n_samples=2000\n",
    "sampler=do_mpc.approximateMPC.Sampler(mpc)\n",
    "sampler.settings.n_samples=n_samples\n",
    "sampler.setup()\n",
    "#sampler.default_sampling()\n",
    "trainer=do_mpc.approximateMPC.Trainer(approx_mpc)\n",
    "trainer.settings.n_samples=n_samples\n",
    "trainer.settings.n_epochs=3000\n",
    "trainer.setup()\n",
    "trainer.default_training()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Closed_loop simulation\n",
    "Visualization and simulation are identical to the MPC class, we only have to use the simulator data."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "np.random.seed(99)\n",
    "# Initial state\n",
    "mpc.reset_history()\n",
    "simulator.reset_history()\n",
    "e = np.ones([model.n_x,1])\n",
    "x0 = np.random.uniform(-3*e,3*e) # Values between +3 and +3 for all states\n",
    "mpc.x0 = x0\n",
    "simulator.x0 = x0\n",
    "estimator.x0 = x0\n",
    "\n",
    "# Use initial state to set the initial guess.\n",
    "mpc.set_initial_guess()\n",
    "for k in range(10):\n",
    "    u0 = approx_mpc.make_step(x0,clip_to_bounds=False)\n",
    "    y_next = simulator.make_step(u0)\n",
    "    x0 = estimator.make_step(y_next)\n",
    "from matplotlib import rcParams\n",
    "rcParams['axes.grid'] = True\n",
    "rcParams['font.size'] = 18\n",
    "fig, ax, graphics = do_mpc.graphics.default_plot(simulator.data, figsize=(16,9))\n",
    "graphics.plot_results()\n",
    "graphics.reset_axes()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Calculate X_in\n",
    "What we require is a set of X_in in which we guarantee to safely use the AMPC\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'trainer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[1], line 5\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mpathlib\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m Path\n\u001B[0;32m      4\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mtorch\u001B[39;00m\n\u001B[1;32m----> 5\u001B[0m data_dir\u001B[38;5;241m=\u001B[39m\u001B[43mtrainer\u001B[49m\u001B[38;5;241m.\u001B[39msettings\u001B[38;5;241m.\u001B[39mdata_dir\n\u001B[0;32m      6\u001B[0m data_dir \u001B[38;5;241m=\u001B[39m Path(data_dir)\n\u001B[0;32m      7\u001B[0m data_dir \u001B[38;5;241m=\u001B[39m data_dir\u001B[38;5;241m.\u001B[39mjoinpath(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdata_n\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mstr\u001B[39m(n_samples) \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_opt.pkl\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[1;31mNameError\u001B[0m: name 'trainer' is not defined"
     ]
    }
   ],
   "source": [
    "import polytope\n",
    "import pickle as pkl\n",
    "from pathlib import Path\n",
    "import torch\n",
    "data_dir=trainer.settings.data_dir\n",
    "data_dir = Path(data_dir)\n",
    "data_dir = data_dir.joinpath(\"data_n\" + str(n_samples) + \"_opt.pkl\")\n",
    "\n",
    "with open(data_dir, \"rb\") as f:\n",
    "    dataset = pkl.load(f)\n",
    "x0 = torch.tensor(dataset[\"x0\"], dtype=trainer.approx_mpc.torch_data_type).reshape(\n",
    "            -1, trainer.approx_mpc.mpc.model.n_x\n",
    "        )\n",
    "x0=np.array(x0.detach().cpu())\n",
    "plt.scatter(x0[:,0],x0[:,1])\n",
    "N_pred=3\n",
    "C_in=invariant_mat\n",
    "c_in=one_vec\n",
    "plot_polygon(verts,color='r',alpha=0.4,resize=True)\n",
    "for k in range(N_pred):\n",
    "    X_mat=np.zeros((len(F)+len(G)+len(C_in),3))\n",
    "    X_mat[0:F.shape[0],0:F.shape[1]]=F\n",
    "    X_mat[F.shape[0]:F.shape[0]+G.shape[0],F.shape[1]:F.shape[1]+G.shape[1]]=G\n",
    "    #X_mat[6:8,3:4]=G\n",
    "    #X_mat[8:10,4:5]=G\n",
    "    #X_mat[10:14,0:3]=np.concatenate((F@A,F@B),axis=1)\n",
    "    #X_mat[14:18,0:4]=np.concatenate((F@A**2,F@A@B,F@B),axis=1)\n",
    "    X_mat[F.shape[0]+G.shape[0]:F.shape[0]+G.shape[0]+len(C_in),0:F.shape[1]+G.shape[1]]=np.concatenate((C_in@A,C_in@B),axis=1)#,invariant_mat@A**2@B,invariant_mat@A@B\n",
    "    ones=np.concatenate((np.ones((F.shape[0]+G.shape[0],1)),c_in),axis=0)\n",
    "    #plot_polygon(verts,color='r',alpha=0.4,resize=True)\n",
    "\n",
    "    verts_new=compute_polytope_vertices(X_mat,ones)\n",
    "    verts_projected=[verts_new[k][0:model.n_x] for k in range(len(verts_new))]\n",
    "    #print(verts_projected)\n",
    "    poly=polytope.qhull(np.array(verts_projected))\n",
    "    C_in=poly.A\n",
    "    c_in=poly.b.reshape((len(poly.b),1))\n",
    "    #print(c_in)\n",
    "plot_polygon(verts_projected,resize=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Output Range analysis for U_1 and forward propagation for X_1\n",
    "Next, we prepare the first optimization problem to certify the output range analysis"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[2], line 4\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mcvxpy\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mas\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mcp\u001B[39;00m\n\u001B[0;32m      2\u001B[0m M\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1e5\u001B[39m\n\u001B[1;32m----> 4\u001B[0m u_res\u001B[38;5;241m=\u001B[39m\u001B[43mnp\u001B[49m\u001B[38;5;241m.\u001B[39mzeros((\u001B[38;5;28mlen\u001B[39m(G),\u001B[38;5;241m1\u001B[39m))\n\u001B[0;32m      5\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mlen\u001B[39m(G)):\n\u001B[0;32m      6\u001B[0m     t\u001B[38;5;241m=\u001B[39mcp\u001B[38;5;241m.\u001B[39mVariable(n_l, integer\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n",
      "\u001B[1;31mNameError\u001B[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "import cvxpy as cp\n",
    "M=1e5\n",
    "\n",
    "u_res=np.zeros((len(G),1))\n",
    "for i in range(len(G)):\n",
    "    t=cp.Variable(n_l, integer=True)\n",
    "    z=cp.Variable(n_l)\n",
    "    u0=cp.Variable(model.n_u)\n",
    "    #print(G[i]*u0)\n",
    "    x0=cp.Variable(model.n_x)\n",
    "    W_1=approx_mpc.net.state_dict()['layers.0.weight']\n",
    "    b_1=approx_mpc.net.state_dict()['layers.0.bias']\n",
    "    W_2=approx_mpc.net.state_dict()['layers.2.weight']\n",
    "    b_2=approx_mpc.net.state_dict()['layers.2.bias']\n",
    "\n",
    "    objective = cp.Maximize(G[i]@u0)\n",
    "    prob = cp.Problem(objective,[x0@W_1.T+b_1 <= z,0<=z, x0@W_1.T+b_1+M*t>=z,M*(np.ones(n_l)-t)>=z,t<=1,t>=0,C_in@x0<=c_in,u0==z@W_2.T+b_2])\n",
    "    prob.solve()\n",
    "    u_res[i]=u0.value\n",
    "    print(x0.value)\n",
    "c_u=G*u_res\n",
    "print(c_u)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "x=np.array([[-1.63464],[ -2.72462]])\n",
    "print(mpc.make_step(x))\n",
    "print(approx_mpc.make_step(x,clip_to_bounds=False))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Output Range analysis for k=1\n",
    "What we require is a second optimization problem that does a set range analysis for k steps"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "def evaluate_set(C_in,c_in,k,C_out):\n",
    "    W_1=approx_mpc.net.state_dict()['layers.0.weight']\n",
    "    b_1=approx_mpc.net.state_dict()['layers.0.bias']\n",
    "    W_2=approx_mpc.net.state_dict()['layers.2.weight']\n",
    "    b_2=approx_mpc.net.state_dict()['layers.2.bias']\n",
    "    M=1e5\n",
    "    xki_res=np.zeros((len(C_out),model.n_x))\n",
    "    for i in range(len(C_out)):\n",
    "        constraints=[]\n",
    "        t=cp.Variable((k,n_l), integer=True)\n",
    "        z0=cp.Variable((k,model.n_x))\n",
    "        z1=cp.Variable((k,n_l))\n",
    "        u=cp.Variable((k,model.n_u))\n",
    "        x0=cp.Variable(model.n_x)\n",
    "        xki=cp.Variable(model.n_x)\n",
    "        constraints.append(C_in@x0<=c_in)\n",
    "        constraints.append(A@z0[k-1]+B@u[k-1]==xki)\n",
    "        constraints.append(z0[0]==x0)\n",
    "        for j in range(k):\n",
    "            if j>0:\n",
    "                constraints.append(z0[j]==A@z0[j-1]+B@u[j-1])\n",
    "            constraints.append(z0[j]@W_1.T+b_1 <= z1[j])\n",
    "            constraints.append(z1[j]>=0)\n",
    "            constraints.append(z0[j]@W_1.T+b_1 + M*t[j] >= z1[j])\n",
    "            constraints.append(M*(np.ones(n_l)-t[j])>=z1[j])\n",
    "            constraints.append(t[j]<=1)\n",
    "            constraints.append(t[j]>=0)\n",
    "            constraints.append(u[j]==z1[j]@W_2.T+b_2)\n",
    "        objective = cp.Maximize(C_out[i]@xki)\n",
    "        prob = cp.Problem(objective,constraints)\n",
    "        prob.solve(verbose=False)\n",
    "        xki_res[i]=xki.value\n",
    "        #print(xki.value)\n",
    "    return xki_res\n",
    "xki_res=evaluate_set(C_in,c_in,1,C_in)\n",
    "#print(xki_res)\n",
    "c_x=np.zeros((len(C_in),1))\n",
    "for m in range(len(C_in)):\n",
    "    c_x[m]=C_in[m,:]@xki_res[m,:].reshape((model.n_x,1))\n",
    "\n",
    "vertices_x=compute_polytope_vertices(C_in,c_x)\n",
    "vertices_inv=compute_polytope_vertices(C_in,c_in)\n",
    "plot_polygon(vertices_x,resize=True)\n",
    "plot_polygon(vertices_inv,resize=True,color='r')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Stability with LQR adaption of neural network\n",
    "Now we have a feasible controller. For stability the controller needs to bring the system in a terminal set after some k steps. Secondly, we also need to ensure that within this terminal set we will reach the origin. While the first part can be easily verified with the same optimization problem we used for the recursive feasibility, the second part is not in general true for neural networks.\n",
    "At first, we need the intersection of the terminal set with the region around the origin where there is no change in the ReLU activation functions of the neural network. Lets calculate this region"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "x1=np.linspace(-10,10,200)\n",
    "fig,ax=plt.subplots()\n",
    "for k in range(len(W_1)):\n",
    "    W_1_k_1=W_1[k,0]\n",
    "    W_1_k_2=W_1[k,1]\n",
    "    b_1_k=b_1[k]\n",
    "    x2=(b_1_k-W_1_k_1*x1)/W_1_k_2\n",
    "    plt.plot(x1,x2)\n",
    "z_1=torch.Tensor([0,0])@W_1.T+b_1\n",
    "gamma=np.array((b_1<0).detach()).reshape(-1,1)\n",
    "\n",
    "print(np.array(b_1.detach().cpu()))\n",
    "lines=list(np.concatenate((np.array(W_1.detach().cpu()),np.array(b_1.detach().cpu()).reshape((-1,1))),axis=1))\n",
    "vertices_list=[]\n",
    "for l1, l2 in combinations(lines, 2):\n",
    "    A = np.array([[l1[0], l1[1]], [l2[0], l2[1]]])\n",
    "    b = np.array([l1[2], l2[2]])\n",
    "\n",
    "    if np.linalg.det(A) != 0:\n",
    "        x = np.linalg.solve(A, b)\n",
    "        if x[0]<4 and x[0]>-6 and x[1]<3 and x[1]>-3:\n",
    "            vertices_list.append(x)\n",
    "            plt.plot(x[0], x[1], 'ro')\n",
    "            print(x[1])\n",
    "        else:\n",
    "            plt.plot(x[0], x[1], 'bo')\n",
    "        #plt.plot(x[0], x[1], 'ro')\n",
    "ax.set_xlim(-7,5)\n",
    "ax.set_ylim(-5,5)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now we can compute our new terminal set as the intersection"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_polygon(vertices_list,resize=True)\n",
    "poly=polytope.qhull(np.array(vertices_list))\n",
    "R_as=poly.A\n",
    "r_as=poly.b.reshape((len(poly.b),1))\n",
    "\n",
    "terminal_set_mat=np.concatenate((invariant_mat,R_as),axis=0)\n",
    "terminal_set_vec=np.concatenate((one_vec,r_as),axis=0)\n",
    "terminal_set=compute_polytope_vertices(terminal_set_mat,terminal_set_vec)\n",
    "plot_polygon(terminal_set,resize=True,color='r')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now we have to adjust the values of the last layer weights such that we can guarentee the stability"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "W_hat=cp.Variable((model.n_u,n_l))\n",
    "b_hat=cp.Variable((model.n_u,1))\n",
    "objective = cp.Minimize(cp.sum_squares(np.array(W_2.cpu().detach())-W_hat)+cp.sum_squares(np.array(b_2.cpu().detach())-b_hat))\n",
    "constraints=[]\n",
    "W_eq=gamma*np.array(W_1.cpu().detach())\n",
    "b_eq=gamma.T*np.array(b_1.cpu().detach())\n",
    "constraints.append(W_hat@W_eq==-K_lqr)\n",
    "constraints.append(W_hat@b_eq.reshape((-1,1))+b_hat==0)\n",
    "prob = cp.Problem(objective,constraints)\n",
    "prob.solve()\n",
    "print(W_hat.value)\n",
    "print(W_2)\n",
    "print(b_2)\n",
    "print(b_hat.value)\n",
    "approx_mpc.net.state_dict()['layers.2.weight']=torch.Tensor(W_hat.value)\n",
    "approx_mpc.net.state_dict()['layers.2.bias']=torch.Tensor(b_hat.value)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's take a lot at the closed-loop response of this new adapted AMPC."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "np.random.seed(99)\n",
    "# Initial state\n",
    "mpc.reset_history()\n",
    "simulator.reset_history()\n",
    "e = np.ones([model.n_x,1])\n",
    "x0 = np.random.uniform(-3*e,3*e) # Values between +3 and +3 for all states\n",
    "mpc.x0 = x0\n",
    "simulator.x0 = x0\n",
    "estimator.x0 = x0\n",
    "\n",
    "# Use initial state to set the initial guess.\n",
    "mpc.set_initial_guess()\n",
    "for k in range(10):\n",
    "    u0 = approx_mpc.make_step(x0,clip_to_bounds=False)\n",
    "    y_next = simulator.make_step(u0)\n",
    "    x0 = estimator.make_step(y_next)\n",
    "from matplotlib import rcParams\n",
    "rcParams['axes.grid'] = True\n",
    "rcParams['font.size'] = 18\n",
    "fig, ax, graphics = do_mpc.graphics.default_plot(simulator.data, figsize=(16,9))\n",
    "graphics.plot_results()\n",
    "graphics.reset_axes()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Output Range analysis for k=6 for guaranteeing stability\n",
    "Finally, we can use the same optimization problem as before to guarantee that we will remain in the terminal set"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "xki_res=evaluate_set(C_in,c_in,2,terminal_set_mat)\n",
    "#print(xki_res)\n",
    "c_x=np.zeros((len(terminal_set_mat),1))\n",
    "for m in range(len(terminal_set_mat)):\n",
    "    c_x[m]=terminal_set_mat[m,:]@xki_res[m,:].reshape((model.n_x,1))\n",
    "\n",
    "#print(c_x)\n",
    "vertices_x=compute_polytope_vertices(terminal_set_mat,c_x)\n",
    "vertices_inv=compute_polytope_vertices(terminal_set_mat,terminal_set_vec)\n",
    "plot_polygon(vertices_x,resize=True)\n",
    "plot_polygon(vertices_inv,resize=True,color='r')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
